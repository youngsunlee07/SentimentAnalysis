{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfbd0c8-48c1-4773-ad47-f0bf80f9b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import bigrams\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea894a5b-fb50-4dab-b737-83efa4a0c351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability of positive sentiment (label=1): 0.5550\n",
      "Prior probability of negative sentiment (label=0): 0.4450\n"
     ]
    }
   ],
   "source": [
    "file_path_sst = r'D:\\IIT(지난학기)\\03_2023_Fall\\Natural Language Processing\\Homework\\HW03\\Data\\SST-2'\n",
    "full_path = os.path.join(file_path_sst, \"train.tsv\")\n",
    "\n",
    "df_sst = pd.read_csv(full_path, delimiter='\\t')\n",
    "\n",
    "df_train, df_temp = train_test_split(df_sst, test_size=0.4, random_state=42)\n",
    "df_validation, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "positive_prob = df_train['label'].mean()\n",
    "negative_prob = 1 - positive_prob\n",
    "\n",
    "print(f\"Prior probability of positive sentiment (label=1): {positive_prob:.4f}\")\n",
    "print(f\"Prior probability of negative sentiment (label=0): {negative_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3e2a5b-4d6b-4610-b63d-e3b85b412216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization of the first sentence in the training set: ['<s>', 'indulges', 'in', 'the', 'worst', 'elements', 'of', 'all', 'of', 'them', '.', '</s>']\n",
      "Vocabulary size of the training set: 14383\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return ['<s>'] + tokens + ['</s>']\n",
    "\n",
    "df_train = df_train.copy()\n",
    "df_train['tokenized'] = df_train['sentence'].apply(tokenize_sentence)\n",
    "print(\"Tokenization of the first sentence in the training set:\", df_train['tokenized'].iloc[0])\n",
    "\n",
    "vocabulary = set()\n",
    "for tokens in df_train['tokenized']:\n",
    "    vocabulary.update(tokens) \n",
    "vocabulary_size = len(vocabulary)\n",
    "print(\"Vocabulary size of the training set:\", vocabulary_size) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4771d3-87fa-4930-9067-2197e05dcffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigram ('<s>', 'the') appears 2599 times in the training set.\n"
     ]
    }
   ],
   "source": [
    "def count_bigrams(tokenized_sequences):\n",
    "    bigram_counts = {}\n",
    "    for sequence in tokenized_sequences:\n",
    "        for w1, w2 in bigrams(sequence):\n",
    "            if w1 not in bigram_counts:\n",
    "                bigram_counts[w1] = {}\n",
    "            bigram_counts[w1][w2] = bigram_counts[w1].get(w2, 0) + 1\n",
    "    return bigram_counts\n",
    "\n",
    "bigram_counts = count_bigrams(df_train['tokenized'])\n",
    "\n",
    "start_with_the_count = bigram_counts['<s>'].get('the', 0)\n",
    "print(f\"The bigram ('<s>', 'the') appears {start_with_the_count} times in the training set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b8ce29-a936-4146-9d83-661495910398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of 'award' following 'academy' with alpha=0.001: -1.0526\n",
      "Log probability of 'award' following 'academy' with alpha=0.5: -6.3577\n"
     ]
    }
   ],
   "source": [
    "def smoothed_probability(w2, w1, bigram_counts, alpha, vocab_size):\n",
    "    if w1 not in bigram_counts:\n",
    "        return alpha / vocab_size\n",
    "    bigram_count = bigram_counts[w1].get(w2, 0)\n",
    "    unigram_count = sum(bigram_counts[w1].values())\n",
    "    prob = (bigram_count + alpha) / (unigram_count + vocab_size * alpha)\n",
    "    return prob\n",
    "\n",
    "alpha_values = [0.001, 0.5]\n",
    "for alpha in alpha_values:\n",
    "    prob = smoothed_probability(\"award\", \"academy\", bigram_counts, alpha, vocabulary_size)\n",
    "    log_prob = np.log(prob)\n",
    "    print(f\"Log probability of 'award' following 'academy' with alpha={alpha}: {log_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823c966f-3f9d-42c0-9a7b-50a0e1acc505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of the sentence 'this was a really great movie but it was a little too long.': -88.7084\n",
      "Log probability of the sentence 'long too little a was it but movie great really a was this.': -124.9414\n"
     ]
    }
   ],
   "source": [
    "def sentence_log_probability(sentence, bigram_counts, alpha, vocab_size):\n",
    "    tokens = ['<s>'] + word_tokenize(sentence) + ['</s>']\n",
    "    log_prob = 0\n",
    "    for i in range(len(tokens) - 1):\n",
    "        w1, w2 = tokens[i], tokens[i+1]\n",
    "        prob = smoothed_probability(w2, w1, bigram_counts, alpha, vocab_size)\n",
    "        log_prob += np.log(prob)\n",
    "    return log_prob\n",
    "\n",
    "sentences = [\n",
    "    \"this was a really great movie but it was a little too long.\",\n",
    "    \"long too little a was it but movie great really a was this.\"\n",
    "]\n",
    "\n",
    "alpha = 0.5\n",
    "for sentence in sentences:\n",
    "    log_prob = sentence_log_probability(sentence, bigram_counts, alpha, vocabulary_size)\n",
    "    print(f\"Log probability of the sentence '{sentence}': {log_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92fb1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood estimate of the validation set for alpha=0.001: -605525.6633\n",
      "Log likelihood estimate of the validation set for alpha=0.01: -675013.5222\n",
      "Log likelihood estimate of the validation set for alpha=0.1: -809397.7779\n",
      "Log likelihood estimate of the validation set for alpha=0.05: -762345.2684\n",
      "Log likelihood estimate of the validation set for alpha=0.005: -647333.4097\n",
      "\n",
      "The selected alpha value is: 0.001\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.001, 0.01, 0.1, 0.05, 0.005]\n",
    "log_likelihoods = {}\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    total_log_prob = sum(sentence_log_probability(sentence, bigram_counts, alpha, vocabulary_size) for sentence in df_validation['sentence'])\n",
    "    log_likelihoods[alpha] = total_log_prob\n",
    "\n",
    "for alpha, log_likelihood in log_likelihoods.items():\n",
    "    print(f\"Log likelihood estimate of the validation set for alpha={alpha}: {log_likelihood:.4f}\")\n",
    "\n",
    "selected_alpha = max(log_likelihoods, key=log_likelihoods.get)\n",
    "print(f\"\\nThe selected alpha value is: {selected_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ba666c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive sentiment predictions: 7348\n",
      "Number of negative sentiment predictions: 6122\n",
      "\n",
      "Accuracy of the sentiment prediction on the test set: 0.8808\n"
     ]
    }
   ],
   "source": [
    "df_positive = df_train[df_train['label'] == 1]\n",
    "df_negative = df_train[df_train['label'] == 0]\n",
    "\n",
    "bigram_counts_positive = count_bigrams(df_positive['tokenized'])\n",
    "bigram_counts_negative = count_bigrams(df_negative['tokenized'])\n",
    "\n",
    "vocab_size_positive = len(set(token for sequences in df_positive['tokenized'] for token in sequences))\n",
    "vocab_size_negative = len(set(token for sequences in df_negative['tokenized'] for token in sequences))\n",
    "\n",
    "predicted_labels = []\n",
    "for sentence in df_test['sentence']:\n",
    "    positive_score = sentence_log_probability(sentence, bigram_counts_positive, selected_alpha, vocab_size_positive) + np.log(positive_prob)\n",
    "    negative_score = sentence_log_probability(sentence, bigram_counts_negative, selected_alpha, vocab_size_negative) + np.log(negative_prob) \n",
    "    \n",
    "    predicted_label = 1 if positive_score > negative_score else 0 \n",
    "    predicted_labels.append(predicted_label) \n",
    "\n",
    "positive_predictions = sum(predicted_labels) \n",
    "negative_predictions = len(predicted_labels) - positive_predictions \n",
    "\n",
    "print(f\"Number of positive sentiment predictions: {positive_predictions}\") \n",
    "print(f\"Number of negative sentiment predictions: {negative_predictions}\") \n",
    "\n",
    "accuracy = sum(true == pred for true, pred in zip(df_test['label'], predicted_labels)) / len(df_test) \n",
    "print(f\"\\nAccuracy of the sentiment prediction on the test set: {accuracy:.4f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
